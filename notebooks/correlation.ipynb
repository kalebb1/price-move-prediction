{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfad3271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load 7 CSV files from '../data/yfinance_data/'...\n",
      "  Loaded MSFT with 9672 rows.\n",
      "  Loaded NVDA with 6421 rows.\n",
      "  Loaded AMZN with 6846 rows.\n",
      "  Loaded TSLA with 3545 rows.\n",
      "  Loaded META with 2926 rows.\n",
      "  Loaded AAPL with 10998 rows.\n",
      "  Loaded GOOG with 5020 rows.\n",
      "\n",
      "Successfully loaded 7 Stock DataFrames.\n",
      "\n",
      "Head of the first loaded Stock DataFrame (should now have 'Ticker' column and DatetimeIndex):\n",
      "                Open      High       Low     Close  Adj Close      Volume  \\\n",
      "Date                                                                        \n",
      "1986-03-13  0.088542  0.101563  0.088542  0.097222   0.059946  1031788800   \n",
      "1986-03-14  0.097222  0.102431  0.097222  0.100694   0.062087   308160000   \n",
      "1986-03-17  0.100694  0.103299  0.100694  0.102431   0.063158   133171200   \n",
      "1986-03-18  0.102431  0.103299  0.098958  0.099826   0.061552    67766400   \n",
      "1986-03-19  0.099826  0.100694  0.097222  0.098090   0.060482    47894400   \n",
      "\n",
      "            Dividends  Stock Splits Ticker  \n",
      "Date                                        \n",
      "1986-03-13        0.0           0.0   MSFT  \n",
      "1986-03-14        0.0           0.0   MSFT  \n",
      "1986-03-17        0.0           0.0   MSFT  \n",
      "1986-03-18        0.0           0.0   MSFT  \n",
      "1986-03-19        0.0           0.0   MSFT  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 9672 entries, 1986-03-13 to 2024-07-30\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Open          9672 non-null   float64\n",
      " 1   High          9672 non-null   float64\n",
      " 2   Low           9672 non-null   float64\n",
      " 3   Close         9672 non-null   float64\n",
      " 4   Adj Close     9672 non-null   float64\n",
      " 5   Volume        9672 non-null   int64  \n",
      " 6   Dividends     9672 non-null   float64\n",
      " 7   Stock Splits  9672 non-null   float64\n",
      " 8   Ticker        9672 non-null   object \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 755.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "Dataset loaded successfully from '../data/raw_analyst_ratings.csv/raw_analyst_ratings.csv'. Displaying the first 5 rows and info:\n",
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                        date stock  \n",
      "0  2020-06-05 10:30:54-04:00     A  \n",
      "1  2020-06-03 10:45:20-04:00     A  \n",
      "2  2020-05-26 04:30:07-04:00     A  \n",
      "3  2020-05-22 12:45:06-04:00     A  \n",
      "4  2020-05-22 11:38:59-04:00     A  \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1407328 entries, 0 to 1407327\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Unnamed: 0  1407328 non-null  int64 \n",
      " 1   headline    1407328 non-null  object\n",
      " 2   url         1407328 non-null  object\n",
      " 3   publisher   1407328 non-null  object\n",
      " 4   date        1407328 non-null  object\n",
      " 5   stock       1407328 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 64.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re # For regular expressions to extract ticker from filename\n",
    "\n",
    "def load_csv_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Loads all CSV files from a given folder into a list of DataFrames.\n",
    "    Adds a 'Ticker' column to each DataFrame, inferred from the filename.\n",
    "    Ensures 'Date' column is datetime index.\n",
    "    \"\"\"\n",
    "    csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "    loaded_dataframes = []\n",
    "\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in '{folder_path}'.\")\n",
    "        return loaded_dataframes\n",
    "\n",
    "    print(f\"Attempting to load {len(csv_files)} CSV files from '{folder_path}'...\")\n",
    "    for file_path in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # --- Extract Ticker from filename and add as a column ---\n",
    "            # Corrected Regex: Matches characters at the start until an underscore, then '.csv'\n",
    "            # For 'MSFT_historical_data.csv', it will capture 'MSFT'.\n",
    "            filename = os.path.basename(file_path)\n",
    "            ticker_match = re.match(r'([A-Za-z0-9]+)_historical_data\\.csv', filename)\n",
    "            if ticker_match:\n",
    "                ticker_symbol = ticker_match.group(1).upper()\n",
    "                df['Ticker'] = ticker_symbol\n",
    "            else:\n",
    "                print(f\"Warning: Could not extract ticker from filename '{filename}'. Skipping this file.\")\n",
    "                continue # Skip if ticker can't be identified\n",
    "\n",
    "            # --- Ensure 'Date' column is datetime and set as index ---\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "                df.dropna(subset=['Date'], inplace=True) # Remove rows where Date couldn't be parsed\n",
    "                df.set_index('Date', inplace=True)\n",
    "                df.sort_index(inplace=True) # Ensure chronological order\n",
    "            else:\n",
    "                print(f\"Warning: 'Date' column not found in '{filename}'. Skipping this file.\")\n",
    "                continue\n",
    "\n",
    "            loaded_dataframes.append(df)\n",
    "            print(f\"  Loaded {ticker_symbol} with {len(df)} rows.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or processing '{file_path}': {e}. Skipping.\")\n",
    "            pass\n",
    "\n",
    "    return loaded_dataframes\n",
    "\n",
    "# --- Execution for Stock Data ---\n",
    "# PLEASE ENSURE THIS PATH IS CORRECT FOR YOUR STOCK CSVs\n",
    "yfinance_data_folder = '../data/yfinance_data/' \n",
    "all_yfinance_dfs = load_csv_files_from_folder(yfinance_data_folder)\n",
    "\n",
    "print(f\"\\nSuccessfully loaded {len(all_yfinance_dfs)} Stock DataFrames.\")\n",
    "if all_yfinance_dfs:\n",
    "    print(\"\\nHead of the first loaded Stock DataFrame (should now have 'Ticker' column and DatetimeIndex):\")\n",
    "    print(all_yfinance_dfs[0].head())\n",
    "    print(all_yfinance_dfs[0].info())\n",
    "\n",
    "\n",
    "# --- Execution for News Data ---\n",
    "# PLEASE ENSURE THIS PATH IS CORRECT FOR YOUR NEWS CSV\n",
    "news_file_path = '../data/raw_analyst_ratings.csv/raw_analyst_ratings.csv'\n",
    "try:\n",
    "    df_news_original = pd.read_csv(news_file_path) # Renamed to df_news_original for clarity\n",
    "    print(f\"\\n\\nDataset loaded successfully from '{news_file_path}'. Displaying the first 5 rows and info:\")\n",
    "    print(df_news_original.head(5))\n",
    "    print(\"\\n\")\n",
    "    df_news_original.info()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{news_file_path}' not found. Please check the path.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while loading the news dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# From now on, we will work with 'df_news_original' for news processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2ad95b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting News Data Normalization and Alignment for 'df_news_original' ---\n",
      "\n",
      "--- Step 1: Converting 'date' column to Datetime ---\n",
      "News DataFrame after converting 'date' to datetime and dropping NaTs:\n",
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                       date stock  \n",
      "0 2020-06-05 10:30:54-04:00     A  \n",
      "1 2020-06-03 10:45:20-04:00     A  \n",
      "2 2020-05-26 04:30:07-04:00     A  \n",
      "3 2020-05-22 12:45:06-04:00     A  \n",
      "4 2020-05-22 11:38:59-04:00     A  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 55987 entries, 0 to 1407270\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype                    \n",
      "---  ------      --------------  -----                    \n",
      " 0   Unnamed: 0  55987 non-null  int64                    \n",
      " 1   headline    55987 non-null  object                   \n",
      " 2   url         55987 non-null  object                   \n",
      " 3   publisher   55987 non-null  object                   \n",
      " 4   date        55987 non-null  datetime64[ns, UTC-04:00]\n",
      " 5   stock       55987 non-null  object                   \n",
      "dtypes: datetime64[ns, UTC-04:00](1), int64(1), object(4)\n",
      "memory usage: 3.0+ MB\n",
      "None\n",
      "\n",
      "--- Step 2: Normalizing Timestamps to Date Only ---\n",
      "News DataFrame with 'aligned_date' (date-only, timezone-naive):\n",
      "   Unnamed: 0                                           headline  \\\n",
      "0           0            Stocks That Hit 52-Week Highs On Friday   \n",
      "1           1         Stocks That Hit 52-Week Highs On Wednesday   \n",
      "2           2                      71 Biggest Movers From Friday   \n",
      "3           3       46 Stocks Moving In Friday's Mid-Day Session   \n",
      "4           4  B of A Securities Maintains Neutral on Agilent...   \n",
      "\n",
      "                                                 url          publisher  \\\n",
      "0  https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
      "1  https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
      "2  https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
      "3  https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
      "4  https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
      "\n",
      "                       date stock              aligned_date  \n",
      "0 2020-06-05 10:30:54-04:00     A 2020-06-05 00:00:00-04:00  \n",
      "1 2020-06-03 10:45:20-04:00     A 2020-06-03 00:00:00-04:00  \n",
      "2 2020-05-26 04:30:07-04:00     A 2020-05-26 00:00:00-04:00  \n",
      "3 2020-05-22 12:45:06-04:00     A 2020-05-22 00:00:00-04:00  \n",
      "4 2020-05-22 11:38:59-04:00     A 2020-05-22 00:00:00-04:00  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 55987 entries, 0 to 1407270\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype                    \n",
      "---  ------        --------------  -----                    \n",
      " 0   Unnamed: 0    55987 non-null  int64                    \n",
      " 1   headline      55987 non-null  object                   \n",
      " 2   url           55987 non-null  object                   \n",
      " 3   publisher     55987 non-null  object                   \n",
      " 4   date          55987 non-null  datetime64[ns, UTC-04:00]\n",
      " 5   stock         55987 non-null  object                   \n",
      " 6   aligned_date  55987 non-null  datetime64[ns, UTC-04:00]\n",
      "dtypes: datetime64[ns, UTC-04:00](2), int64(1), object(4)\n",
      "memory usage: 3.4+ MB\n",
      "None\n",
      "\n",
      "--- Step 3: Cleaning and Standardizing 'stock' column ---\n",
      "Filtered for desired big tech tickers. Removed 55937 rows.\n",
      "News DataFrame after standardizing and filtering 'stock' column:\n",
      "      Unnamed: 0                                           headline  \\\n",
      "6680        7120  Tech Stocks And FAANGS Strong Again To Start D...   \n",
      "6681        7121      10 Biggest Price Target Changes For Wednesday   \n",
      "6682        7122  Benzinga Pro's Top 5 Stocks To Watch For Wed.,...   \n",
      "6683        7123  Deutsche Bank Maintains Buy on Apple, Raises P...   \n",
      "6684        7124  Apple To Let Users Trade In Their Mac Computer...   \n",
      "\n",
      "                                                    url          publisher  \\\n",
      "6680  https://www.benzinga.com/government/20/06/1622...         JJ Kinahan   \n",
      "6681  https://www.benzinga.com/analyst-ratings/price...         Lisa Levin   \n",
      "6682  https://www.benzinga.com/short-sellers/20/06/1...  Benzinga Newsdesk   \n",
      "6683  https://www.benzinga.com/news/20/06/16219873/d...  Benzinga Newsdesk   \n",
      "6684  https://www.benzinga.com/news/20/06/16218697/a...      Neer Varshney   \n",
      "\n",
      "                          date stock              aligned_date  \n",
      "6680 2020-06-10 11:33:26-04:00  AAPL 2020-06-10 00:00:00-04:00  \n",
      "6681 2020-06-10 08:14:08-04:00  AAPL 2020-06-10 00:00:00-04:00  \n",
      "6682 2020-06-10 07:53:47-04:00  AAPL 2020-06-10 00:00:00-04:00  \n",
      "6683 2020-06-10 07:19:25-04:00  AAPL 2020-06-10 00:00:00-04:00  \n",
      "6684 2020-06-10 06:27:11-04:00  AAPL 2020-06-10 00:00:00-04:00  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50 entries, 6680 to 1255230\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype                    \n",
      "---  ------        --------------  -----                    \n",
      " 0   Unnamed: 0    50 non-null     int64                    \n",
      " 1   headline      50 non-null     object                   \n",
      " 2   url           50 non-null     object                   \n",
      " 3   publisher     50 non-null     object                   \n",
      " 4   date          50 non-null     datetime64[ns, UTC-04:00]\n",
      " 5   stock         50 non-null     object                   \n",
      " 6   aligned_date  50 non-null     datetime64[ns, UTC-04:00]\n",
      "dtypes: datetime64[ns, UTC-04:00](2), int64(1), object(4)\n",
      "memory usage: 3.1+ KB\n",
      "None\n",
      "\n",
      "--- Step 4: Aggregating News per Day per Ticker ---\n",
      "Aggregated News DataFrame (first 5 rows):\n",
      "               aligned_date stock  news_count  \\\n",
      "0 2020-05-31 00:00:00-04:00  NVDA           1   \n",
      "1 2020-06-02 00:00:00-04:00  NVDA           2   \n",
      "2 2020-06-04 00:00:00-04:00  GOOG           1   \n",
      "3 2020-06-05 00:00:00-04:00  GOOG           3   \n",
      "4 2020-06-08 00:00:00-04:00  GOOG           1   \n",
      "\n",
      "                                      first_headline  \n",
      "0  Semiconductor Industry to Lobby for Billions t...  \n",
      "1  Why BofA Recommends Buying GPU Plays AMD and N...  \n",
      "2  UPDATE: Chinese Government-Linked Hackers Rece...  \n",
      "3  CNBC Publishes Article Titled: States are Lean...  \n",
      "4  Starting This Week, Testing Center Alerts Will...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype                    \n",
      "---  ------          --------------  -----                    \n",
      " 0   aligned_date    15 non-null     datetime64[ns, UTC-04:00]\n",
      " 1   stock           15 non-null     object                   \n",
      " 2   news_count      15 non-null     int64                    \n",
      " 3   first_headline  15 non-null     object                   \n",
      "dtypes: datetime64[ns, UTC-04:00](1), int64(1), object(2)\n",
      "memory usage: 612.0+ bytes\n",
      "None\n",
      "\n",
      "--- Step 5: Final Preparation: Rename 'aligned_date' to 'Date' and Set as Index ---\n",
      "Final Aggregated News DataFrame ready for merging (first 5 rows):\n",
      "                          stock  news_count  \\\n",
      "Date                                          \n",
      "2020-05-31 00:00:00-04:00  NVDA           1   \n",
      "2020-06-02 00:00:00-04:00  NVDA           2   \n",
      "2020-06-04 00:00:00-04:00  GOOG           1   \n",
      "2020-06-05 00:00:00-04:00  GOOG           3   \n",
      "2020-06-08 00:00:00-04:00  GOOG           1   \n",
      "\n",
      "                                                              first_headline  \n",
      "Date                                                                          \n",
      "2020-05-31 00:00:00-04:00  Semiconductor Industry to Lobby for Billions t...  \n",
      "2020-06-02 00:00:00-04:00  Why BofA Recommends Buying GPU Plays AMD and N...  \n",
      "2020-06-04 00:00:00-04:00  UPDATE: Chinese Government-Linked Hackers Rece...  \n",
      "2020-06-05 00:00:00-04:00  CNBC Publishes Article Titled: States are Lean...  \n",
      "2020-06-08 00:00:00-04:00  Starting This Week, Testing Center Alerts Will...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15 entries, 2020-05-31 00:00:00-04:00 to 2020-06-10 00:00:00-04:00\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   stock           15 non-null     object\n",
      " 1   news_count      15 non-null     int64 \n",
      " 2   first_headline  15 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 480.0+ bytes\n",
      "None\n",
      "\n",
      "--- News Data Normalization and Alignment Complete ---\n",
      "The 'aggregated_news_df' is now prepared and ready to be merged with your historical stock data (all_yfinance_dfs).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Assuming df_news_original is loaded from the previous block\n",
    "\n",
    "print(\"\\n--- Starting News Data Normalization and Alignment for 'df_news_original' ---\")\n",
    "\n",
    "# --- Step 1: Standardize 'date' Column to Datetime Objects ---\n",
    "# Explanation: Your news 'date' column contains full timestamps with timezone offsets\n",
    "# (e.g., '2020-06-05 10:30:54-04:00'). For Pandas to efficiently work with dates\n",
    "# and for proper alignment, it must be converted into a standardized `datetime` format.\n",
    "# `errors='coerce'` is crucial: if any date string cannot be parsed, it will be\n",
    "# converted to `NaT` (Not a Time/Date) instead of raising an error.\n",
    "# We then drop these `NaT` entries because they cannot be aligned.\n",
    "# Note: pd.to_datetime handles timezone offsets automatically, resulting in timezone-aware datetimes.\n",
    "print(\"\\n--- Step 1: Converting 'date' column to Datetime ---\")\n",
    "df_news_processed = df_news_original.copy() # Work on a copy of the original news DataFrame\n",
    "df_news_processed['date'] = pd.to_datetime(df_news_processed['date'], errors='coerce')\n",
    "# Drop rows where date parsing failed (i.e., 'date' became NaT)\n",
    "df_news_processed.dropna(subset=['date'], inplace=True)\n",
    "\n",
    "print(\"News DataFrame after converting 'date' to datetime and dropping NaTs:\")\n",
    "print(df_news_processed.head())\n",
    "print(df_news_processed.info())\n",
    "\n",
    "\n",
    "# --- Step 2: Normalize Timestamps to Date Only ---\n",
    "# Explanation: Stock data is typically daily (one data point per day) and does not\n",
    "# include time components or timezone information (it's usually market-specific).\n",
    "# Your news dates currently include exact times and timezone offsets.\n",
    "# To align news perfectly with daily stock data, we need to strip both the time\n",
    "# component and the timezone information, leaving only the calendar date\n",
    "# (e.g., '2020-06-05 10:30:54-04:00' becomes '2020-06-05 00:00:00').\n",
    "# `.dt.normalize()` handles this: it converts to timezone-naive datetime and sets time to midnight.\n",
    "print(\"\\n--- Step 2: Normalizing Timestamps to Date Only ---\")\n",
    "df_news_processed['aligned_date'] = df_news_processed['date'].dt.normalize()\n",
    "print(\"News DataFrame with 'aligned_date' (date-only, timezone-naive):\")\n",
    "print(df_news_processed.head())\n",
    "print(df_news_processed.info())\n",
    "\n",
    "\n",
    "# --- Step 3: Standardize 'stock' Column ---\n",
    "# Explanation: This column identifies which company the news refers to. It's crucial\n",
    "# that these entries (e.g., 'A', 'MSFT') are clean and consistent. Stock ticker\n",
    "# symbols are typically uppercase. We'll convert them to string type, then to\n",
    "# uppercase, and strip any leading/trailing whitespace to ensure uniformity.\n",
    "# We'll also drop any rows where the 'stock' symbol is missing or becomes empty,\n",
    "# as we cannot link such news to a specific company.\n",
    "print(\"\\n--- Step 3: Cleaning and Standardizing 'stock' column ---\")\n",
    "df_news_processed['stock'] = df_news_processed['stock'].astype(str).str.upper().str.strip()\n",
    "df_news_processed.dropna(subset=['stock'], inplace=True) # Drop if 'stock' is NaN/empty after cleaning\n",
    "\n",
    "# It's a good idea to ensure only the desired big tech tickers are present if you don't\n",
    "# want to process news for other stocks like 'A' (Agilent)\n",
    "desired_big_tech_tickers = ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "initial_rows = len(df_news_processed)\n",
    "df_news_processed = df_news_processed[df_news_processed['stock'].isin(desired_big_tech_tickers)].copy()\n",
    "print(f\"Filtered for desired big tech tickers. Removed {initial_rows - len(df_news_processed)} rows.\")\n",
    "print(\"News DataFrame after standardizing and filtering 'stock' column:\")\n",
    "print(df_news_processed.head())\n",
    "print(df_news_processed.info())\n",
    "\n",
    "\n",
    "# --- Step 4: Aggregate News per Day per Ticker ---\n",
    "# Explanation: On any given 'aligned_date', there might be multiple news articles\n",
    "# for the same stock. To align with a single daily stock price entry,\n",
    "# you need to summarize these multiple news items into a single daily record.\n",
    "# This aggregation consolidates all news for a specific stock on a particular day.\n",
    "# Here, we'll count the number of articles and take the first headline published\n",
    "# on that day for that stock. You could also include sentiment analysis here\n",
    "# if you have a numerical sentiment score derived from your 'sentiment' column.\n",
    "print(\"\\n--- Step 4: Aggregating News per Day per Ticker ---\")\n",
    "aggregated_news_df = df_news_processed.groupby(['aligned_date', 'stock']).agg(\n",
    "    news_count=('headline', 'size'), # Count the number of news articles\n",
    "    first_headline=('headline', lambda x: x.iloc[0]) # Get the first headline of the day for that stock\n",
    "    # If you have a 'sentiment' column and have converted it to numerical scores (e.g., -1, 0, 1),\n",
    "    # you could add: 'avg_sentiment': ('sentiment_score', 'mean')\n",
    ").reset_index() # reset_index moves 'aligned_date' and 'stock' back into regular columns\n",
    "\n",
    "print(\"Aggregated News DataFrame (first 5 rows):\")\n",
    "print(aggregated_news_df.head())\n",
    "print(aggregated_news_df.info())\n",
    "\n",
    "\n",
    "# --- Step 5: Final Preparation: Rename 'aligned_date' to 'Date' and Set as Index ---\n",
    "# Explanation: For efficient and clean merging with your stock DataFrames\n",
    "# (which have their 'Date' as the index, as modified in Step 0), it's a best practice\n",
    "# to also rename the aggregated date column to 'Date' and set it as the index\n",
    "# of this news DataFrame. This prepares it for a direct index-to-index merge.\n",
    "print(\"\\n--- Step 5: Final Preparation: Rename 'aligned_date' to 'Date' and Set as Index ---\")\n",
    "aggregated_news_df.rename(columns={'aligned_date': 'Date'}, inplace=True)\n",
    "aggregated_news_df.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"Final Aggregated News DataFrame ready for merging (first 5 rows):\")\n",
    "print(aggregated_news_df.head())\n",
    "print(aggregated_news_df.info())\n",
    "\n",
    "print(\"\\n--- News Data Normalization and Alignment Complete ---\")\n",
    "print(\"The 'aggregated_news_df' is now prepared and ready to be merged with your historical stock data (all_yfinance_dfs).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161f86cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to /home/ca/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f4452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Sentiment Analysis on News Headlines ---\n",
      "\n",
      "DataFrame state before sentiment analysis (first 5 rows with relevant columns):\n",
      "                          date              aligned_date stock  \\\n",
      "6680 2020-06-10 11:33:26-04:00 2020-06-10 00:00:00-04:00  AAPL   \n",
      "6681 2020-06-10 08:14:08-04:00 2020-06-10 00:00:00-04:00  AAPL   \n",
      "6682 2020-06-10 07:53:47-04:00 2020-06-10 00:00:00-04:00  AAPL   \n",
      "6683 2020-06-10 07:19:25-04:00 2020-06-10 00:00:00-04:00  AAPL   \n",
      "6684 2020-06-10 06:27:11-04:00 2020-06-10 00:00:00-04:00  AAPL   \n",
      "\n",
      "                                               headline  \n",
      "6680  Tech Stocks And FAANGS Strong Again To Start D...  \n",
      "6681      10 Biggest Price Target Changes For Wednesday  \n",
      "6682  Benzinga Pro's Top 5 Stocks To Watch For Wed.,...  \n",
      "6683  Deutsche Bank Maintains Buy on Apple, Raises P...  \n",
      "6684  Apple To Let Users Trade In Their Mac Computer...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50 entries, 6680 to 1255230\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype                    \n",
      "---  ------        --------------  -----                    \n",
      " 0   Unnamed: 0    50 non-null     int64                    \n",
      " 1   headline      50 non-null     object                   \n",
      " 2   url           50 non-null     object                   \n",
      " 3   publisher     50 non-null     object                   \n",
      " 4   date          50 non-null     datetime64[ns, UTC-04:00]\n",
      " 5   stock         50 non-null     object                   \n",
      " 6   aligned_date  50 non-null     datetime64[ns, UTC-04:00]\n",
      "dtypes: datetime64[ns, UTC-04:00](2), int64(1), object(4)\n",
      "memory usage: 3.1+ KB\n",
      "None\n",
      "\n",
      "--- Step 1: Calculating VADER Compound Sentiment Scores ---\n",
      "News DataFrame with 'sentiment_score' (first 5 rows):\n",
      "                                               headline  sentiment_score\n",
      "6680  Tech Stocks And FAANGS Strong Again To Start D...           0.5574\n",
      "6681      10 Biggest Price Target Changes For Wednesday           0.0000\n",
      "6682  Benzinga Pro's Top 5 Stocks To Watch For Wed.,...           0.2023\n",
      "6683  Deutsche Bank Maintains Buy on Apple, Raises P...           0.0000\n",
      "6684  Apple To Let Users Trade In Their Mac Computer...           0.3818\n",
      "\n",
      "--- Step 2: Categorizing Sentiment Labels ---\n",
      "News DataFrame with 'sentiment_label' (first 5 rows):\n",
      "                                               headline  sentiment_score  \\\n",
      "6680  Tech Stocks And FAANGS Strong Again To Start D...           0.5574   \n",
      "6681      10 Biggest Price Target Changes For Wednesday           0.0000   \n",
      "6682  Benzinga Pro's Top 5 Stocks To Watch For Wed.,...           0.2023   \n",
      "6683  Deutsche Bank Maintains Buy on Apple, Raises P...           0.0000   \n",
      "6684  Apple To Let Users Trade In Their Mac Computer...           0.3818   \n",
      "\n",
      "     sentiment_label  \n",
      "6680        positive  \n",
      "6681         neutral  \n",
      "6682        positive  \n",
      "6683         neutral  \n",
      "6684        positive  \n",
      "\n",
      "Summary of sentiment labels:\n",
      "sentiment_label\n",
      "positive    27\n",
      "neutral     20\n",
      "negative     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment analysis complete for individual news headlines.\n",
      "The 'df_news_processed' DataFrame now contains 'sentiment_score' and 'sentiment_label' columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# --- Ensure VADER lexicon is downloaded ---\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    "except nltk.downloader.DownloadError:\n",
    "    print(\"VADER lexicon not found. Downloading...\")\n",
    "    nltk.download('vader_lexicon')\n",
    "    print(\"VADER lexicon downloaded.\")\n",
    "\n",
    "print(\"\\n--- Starting Sentiment Analysis on News Headlines ---\")\n",
    "\n",
    "# --- Initialize the VADER sentiment analyzer ---\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# --- Re-create df_news_processed to ensure it's in the correct state ---\n",
    "\n",
    "# Load the original news data again (assuming it's available from previous blocks)\n",
    "news_file_path = '../data/raw_analyst_ratings.csv/raw_analyst_ratings.csv'\n",
    "try:\n",
    "    df_news_original = pd.read_csv(news_file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{news_file_path}' not found. Cannot perform sentiment analysis.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred loading news data for sentiment analysis: {e}\")\n",
    "    exit()\n",
    "\n",
    "df_news_processed = df_news_original.copy()\n",
    "\n",
    "# Step 1: Standardize 'date' column to Datetime Objects\n",
    "df_news_processed['date'] = pd.to_datetime(df_news_processed['date'], errors='coerce')\n",
    "df_news_processed.dropna(subset=['date'], inplace=True)\n",
    "\n",
    "# Step 2: Normalize Timestamps to Date Only\n",
    "df_news_processed['aligned_date'] = df_news_processed['date'].dt.normalize()\n",
    "\n",
    "# Step 3: Standardize 'stock' Column\n",
    "df_news_processed['stock'] = df_news_processed['stock'].astype(str).str.upper().str.strip()\n",
    "df_news_processed.dropna(subset=['stock'], inplace=True)\n",
    "desired_big_tech_tickers = ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA', 'TSLA']\n",
    "df_news_processed = df_news_processed[df_news_processed['stock'].isin(desired_big_tech_tickers)].copy()\n",
    "# Ensure 'headline' column is string type and handle potential NaNs before sentiment analysis\n",
    "df_news_processed['headline'] = df_news_processed['headline'].astype(str).fillna('')\n",
    "\n",
    "print(\"\\nDataFrame state before sentiment analysis (first 5 rows with relevant columns):\")\n",
    "print(df_news_processed[['date', 'aligned_date', 'stock', 'headline']].head())\n",
    "print(df_news_processed.info())\n",
    "\n",
    "# --- Step 1: Calculate Sentiment Scores for Each Headline ---\n",
    "# Explanation: We define a function that takes a text (headline) and uses VADER\n",
    "# to return a 'compound' sentiment score. The compound score is a normalized\n",
    "# weighted composite score, typically ranging from -1 (most negative) to +1 (most positive).\n",
    "# A score closer to 0 indicates neutrality.\n",
    "print(\"\\n--- Step 1: Calculating VADER Compound Sentiment Scores ---\")\n",
    "\n",
    "def get_vader_sentiment_score(text):\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return 0.0 # Return 0 for empty or non-string headlines\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "# Apply the function to the 'headline' column to create a new 'sentiment_score' column\n",
    "df_news_processed['sentiment_score'] = df_news_processed['headline'].apply(get_vader_sentiment_score)\n",
    "\n",
    "print(\"News DataFrame with 'sentiment_score' (first 5 rows):\")\n",
    "print(df_news_processed[['headline', 'sentiment_score']].head())\n",
    "\n",
    "\n",
    "# --- Step 2: Categorize Sentiment (Optional but helpful for interpretation) ---\n",
    "# Explanation: While a numerical score is good for quantitative analysis,\n",
    "# it's often useful to categorize sentiment into labels like 'positive', 'negative',\n",
    "# and 'neutral' for easier understanding and visualization.\n",
    "# We'll use common thresholds:\n",
    "#   - score >= 0.05: Positive\n",
    "#   - score <= -0.05: Negative\n",
    "#   - otherwise: Neutral (scores between -0.05 and 0.05)\n",
    "print(\"\\n--- Step 2: Categorizing Sentiment Labels ---\")\n",
    "\n",
    "def get_sentiment_label(score):\n",
    "    if score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the categorization function to create a new 'sentiment_label' column\n",
    "df_news_processed['sentiment_label'] = df_news_processed['sentiment_score'].apply(get_sentiment_label)\n",
    "\n",
    "print(\"News DataFrame with 'sentiment_label' (first 5 rows):\")\n",
    "print(df_news_processed[['headline', 'sentiment_score', 'sentiment_label']].head())\n",
    "\n",
    "print(\"\\nSummary of sentiment labels:\")\n",
    "print(df_news_processed['sentiment_label'].value_counts())\n",
    "\n",
    "print(\"\\nSentiment analysis complete for individual news headlines.\")\n",
    "print(\"The 'df_news_processed' DataFrame now contains 'sentiment_score' and 'sentiment_label' columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b7d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Full News Data Processing with Sentiment Analysis ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re # For regular expressions (used in stock data loading if needed)\n",
    "import os # For file path operations\n",
    "import glob # For listing files\n",
    "\n",
    "# --- 0. Ensure NLTK VADER lexicon is downloaded ---\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    "except nltk.downloader.DownloadError:\n",
    "    print(\"VADER lexicon not found. Downloading...\")\n",
    "    nltk.download('vader_lexicon')\n",
    "    print(\"VADER lexicon downloaded.\")\n",
    "\n",
    "print(\"--- Starting Full News Data Processing with Sentiment Analysis ---\")\n",
    "\n",
    "# --- 1. Load the News Data (as per your specified path) ---\n",
    "news_file_path = '../data/raw_analyst_ratings.csv/raw_analyst_ratings.csv'\n",
    "try:\n",
    "    df_news_original = pd.read_csv(news_file_path)\n",
    "    print(f\"\\nNews dataset loaded successfully from '{news_file_path}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: News file '{news_file_path}' not found. Please check the path.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred loading news data: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"Original News DataFrame head:\")\n",
    "print(df_news_original.head())\n",
    "print(\"\\nOriginal News DataFrame info:\")\n",
    "df_news_original.info()\n",
    "\n",
    "\n",
    "# --- 2. Initial News Data Processing (Steps from previous alignment) ---\n",
    "# Create a working copy\n",
    "df_news_processed = df_news_original.copy()\n",
    "\n",
    "# Step 2.1: Standardize 'date' column to Datetime Objects\n",
    "df_news_processed['date'] = pd.to_datetime(df_news_processed['date'], errors='coerce')\n",
    "df_news_processed.dropna(subset=['date'], inplace=True)\n",
    "print(\"\\nAfter date conversion and NaT drop:\")\n",
    "print(df_news_processed.info())\n",
    "\n",
    "# Step 2.2: Normalize Timestamps to Date Only\n",
    "df_news_processed['aligned_date'] = df_news_processed['date'].dt.normalize()\n",
    "print(\"\\nAfter date normalization:\")\n",
    "print(df_news_processed.info())\n",
    "\n",
    "# Step 2.3: Standardize 'stock' Column and filter for big tech\n",
    "df_news_processed['stock'] = df_news_processed['stock'].astype(str).str.upper().str.strip()\n",
    "df_news_processed.dropna(subset=['stock'], inplace=True)\n",
    "desired_big_tech_tickers = ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA', 'TSLA'] # Ensure these match your stock files\n",
    "initial_rows = len(df_news_processed)\n",
    "df_news_processed = df_news_processed[df_news_processed['stock'].isin(desired_big_tech_tickers)].copy()\n",
    "print(f\"\\nAfter stock standardization and filtering for {len(desired_big_tech_tickers)} big tech tickers. Removed {initial_rows - len(df_news_processed)} rows.\")\n",
    "print(df_news_processed.info())\n",
    "\n",
    "# Ensure 'headline' column is string type and handle potential NaNs before sentiment analysis\n",
    "df_news_processed['headline'] = df_news_processed['headline'].astype(str).fillna('')\n",
    "\n",
    "\n",
    "# --- 3. Sentiment Analysis on Headlines ---\n",
    "print(\"\\n--- Performing Sentiment Analysis on Headlines ---\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_sentiment_score(text):\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return 0.0 # Return 0 for empty or non-string headlines\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "df_news_processed['sentiment_score'] = df_news_processed['headline'].apply(get_vader_sentiment_score)\n",
    "\n",
    "print(\"News DataFrame with 'sentiment_score' (first 5 rows with headline and score):\")\n",
    "print(df_news_processed[['headline', 'sentiment_score']].head())\n",
    "print(f\"Sentiment analysis complete. Added 'sentiment_score' column. Total rows: {len(df_news_processed)}\")\n",
    "\n",
    "\n",
    "# --- 4. Re-aggregate News per Day per Ticker (INCLUDING SENTIMENT) ---\n",
    "print(\"\\n--- Re-aggregating News Data, including Mean Sentiment Score ---\")\n",
    "aggregated_news_df = df_news_processed.groupby(['aligned_date', 'stock']).agg(\n",
    "    news_count=('headline', 'size'), # Count number of headlines\n",
    "    first_headline=('headline', lambda x: x.iloc[0]), # Get the first headline\n",
    "    avg_sentiment=('sentiment_score', 'mean') # Calculate the mean sentiment for the day/stock\n",
    ").reset_index() # Moves 'aligned_date' and 'stock' back to columns\n",
    "\n",
    "print(\"Aggregated News DataFrame (first 5 rows, including avg_sentiment):\")\n",
    "print(aggregated_news_df.head())\n",
    "print(f\"Aggregated DataFrame shape: {aggregated_news_df.shape}\")\n",
    "\n",
    "\n",
    "# --- 5. Final Preparation: Rename 'aligned_date' to 'Date' and Set as Index ---\n",
    "print(\"\\n--- Final Preparation: Renaming 'aligned_date' to 'Date' and Setting as Index ---\")\n",
    "aggregated_news_df.rename(columns={'aligned_date': 'Date'}, inplace=True)\n",
    "aggregated_news_df.set_index('Date', inplace=True)\n",
    "\n",
    "print(\"Final 'aggregated_news_df' ready for merging with stock data:\")\n",
    "print(aggregated_news_df.head(10)) # Display more rows to see some variety\n",
    "print(\"\\nFinal 'aggregated_news_df' info:\")\n",
    "print(aggregated_news_df.info())\n",
    "\n",
    "print(\"\\n--- News Data Processing with Sentiment Analysis Complete ---\")\n",
    "print(\"You can now see the 'news_count' and 'avg_sentiment' for each stock on each trading day.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a50658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
